{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/github/sk-classroom/asc-transformers/blob/main/assignments/assignment_01.ipynb)\n",
    "\n",
    "In this notebook, we will be creating a seq2seq model for machine translation. \n",
    "References: \n",
    "- [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215)\n",
    "- [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473)\n",
    "\n",
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are using Google Colab or local environments, install the following packages:\n",
    "# !pip install bpemb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Data\n",
    "\n",
    "The seq2seq will be trained on bilingual sentence pairs taken from [ManyThings.org](https://www.manythings.org/anki/). The dataset contains sentence pairs in the format of \"source language sentence\" and \"target language sentence\". \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Va !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Marche.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go.</td>\n",
       "      <td>En route !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Bouge !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Salut !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>We've made it.</td>\n",
       "      <td>Nous avons réussi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>We've made it.</td>\n",
       "      <td>Nous y sommes parvenus.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>We've matured.</td>\n",
       "      <td>Nous avons mûri.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>We've no time.</td>\n",
       "      <td>Nous n'avons pas le temps.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>We've refused.</td>\n",
       "      <td>Nous avons refusé.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              source                      target\n",
       "0                Go.                        Va !\n",
       "1                Go.                     Marche.\n",
       "2                Go.                  En route !\n",
       "3                Go.                     Bouge !\n",
       "4                Hi.                     Salut !\n",
       "...              ...                         ...\n",
       "9995  We've made it.          Nous avons réussi.\n",
       "9996  We've made it.     Nous y sommes parvenus.\n",
       "9997  We've matured.            Nous avons mûri.\n",
       "9998  We've no time.  Nous n'avons pas le temps.\n",
       "9999  We've refused.          Nous avons refusé.\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "url = \"https://www.manythings.org/anki/fra-eng.zip\"\n",
    "\n",
    "root = \"..\"\n",
    "#root = \"https://raw.githubusercontent.com/sk-classroom/asc-tranformers/main\"\n",
    "\n",
    "train_data = pd.read_csv(f\"{root}/data/fra.txt\", sep = \"\\t\", header = None, names = [\"source\", \"target\"], usecols=[0,1])\n",
    "train_data = train_data.head(10000)\n",
    "train_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we will use pre-trained word embedding from [BPEMB](https://github.com/bheinzerling/bpemb) to represent the phrases into vectors. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bpemb import BPEmb\n",
    "\n",
    "en_bpemb = BPEmb(lang=\"en\", vs=1000)\n",
    "fr_bpemb = BPEmb(lang=\"fr\", vs=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized by English tokenizer: ['▁h', 'i', ',', '▁m', 'y', '▁name', '▁is', '▁john']  (total = 8  tokens)\n",
      "Tokenized by French tokenizer: ['▁h', 'i', ',', '▁m', 'y', '▁n', 'a', 'me', '▁', 'is', '▁jo', 'hn']  (total = 12  tokens)\n",
      "English token vectors (print only the first 5 dimensions):\n",
      " [[ 1.12179e-01 -4.30870e-02  1.14996e-01  2.64587e-01  3.01172e-01]\n",
      " [-2.38435e-01  5.12301e-01  3.68039e-01  9.17290e-02  7.29746e-01]\n",
      " [ 6.39370e-02  3.46926e-01 -2.20221e-01 -7.27650e-02 -2.92797e-01]\n",
      " [ 3.08670e-02  3.71310e-01  5.02850e-02  3.94628e-01  6.34760e-02]\n",
      " [-3.44800e-03  2.63790e-02 -8.72300e-03 -1.22588e-01  6.26850e-01]\n",
      " [ 3.50000e-05 -5.50390e-02  2.03372e-01  3.82068e-01  2.58657e-01]\n",
      " [-1.14224e-01 -4.92930e-02 -2.50380e-01 -4.91210e-02  2.58080e-02]\n",
      " [-5.07085e-01 -6.08790e-02 -3.25503e-01 -1.10300e-03 -3.38848e-01]]\n"
     ]
    }
   ],
   "source": [
    "text = \"Hi, my name is John\"\n",
    "\n",
    "en_tokens = en_bpemb.encode(text)\n",
    "\n",
    "print(\"Tokenized by English tokenizer:\", en_tokens, \" (total =\", len(en_tokens), \" tokens)\")\n",
    "\n",
    "fr_tokens = fr_bpemb.encode(text)\n",
    "print(\"Tokenized by French tokenizer:\", fr_tokens, \" (total =\", len(fr_tokens), \" tokens)\")\n",
    "\n",
    "# Generate the sequence of token embeddings\n",
    "# Passing the tokens through en_bpemb.emb generate the token embeddings\n",
    "print(\"English token vectors (print only the first 5 dimensions):\\n\", en_bpemb.emb[en_tokens][:, :5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a seq2seq model\n",
    "\n",
    "## Tokenizations\n",
    "\n",
    "Now, let's make a simple seq2seq model consisting of an encoder and a decoder. To understand how they work, let's consider the following example: \n",
    "\n",
    "```\n",
    "Input: I am a student\n",
    "Target output: Je suis étudiant\n",
    "```\n",
    "\n",
    "In seq2seq, we will insert two special tokens, namely `[SOS]` (Start of Sequence) and `[EOS]` (End of Sequence) to the input and the output sequences to inform the model when to start and stop. For example,  \n",
    "\n",
    "```\n",
    "Input: I am a student [EOS]\n",
    "Target output: [SOS] Je suis étudiant [EOS]\n",
    "```\n",
    "\n",
    "** Note: [SOS] is not prepended to the input sequence on purpose, because it does not much contribute to encoding. \n",
    "\n",
    "## Padding & Truncation \n",
    "\n",
    "We will pack multiple sequences into a single fixed-size tensor of size <`batch_size` x `max_length` x `n_dim`> shown below. \n",
    "\n",
    "- `batch_size` is the number of sentences in the batch\n",
    "- `max_length` is the maximum length of the sentences in the batch\n",
    "- `n_dim` is the dimension of the subword vectors\n",
    "\n",
    "To make the sequences have the same length, we will pad or truncate the sequences. Namely,  \n",
    "**Padding** is the process of adding zeros to the sequences to make them have the same length. \n",
    "**Truncation** is the process of removing the tokens from the sequences to make them have the same length. \n",
    "\n",
    "One can pad the sequences with zeros in the begining or the end, and the choice does not affect the RNNs in theory. Yet, in practice, it is known that post padding (i.e., padding with zeros at the end) is more effective. (See [Dwarampudi & Reddy, 2019](https://arxiv.org/abs/1903.07288)). \n",
    "\n",
    "![image.png](images/padding.jpg)\n",
    "\n",
    "## Implement the tokenizer \n",
    "\n",
    "Let's make our tokenizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subword token ids:\n",
      " tensor([[1002, 1002, 1002, 1002, 1002, 1002, 1002, 1002, 1002, 1002, 1002, 1002,\n",
      "         1002, 1002, 1002, 1002, 1002, 1002, 1002, 1002, 1002, 1002, 1002, 1000,\n",
      "           21,  191,  357,  945,  915, 1001],\n",
      "        [1002, 1002, 1002, 1002, 1002, 1002, 1002, 1002, 1002, 1002, 1002, 1002,\n",
      "         1002, 1002, 1002, 1002, 1002, 1002, 1002, 1002, 1002, 1002, 1002, 1000,\n",
      "          762,   90,  357,  945,  915, 1001]])\n",
      "Shape: torch.Size([2, 30])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import linalg\n",
    "import torch\n",
    "\n",
    "class Tokenizer:\n",
    "\n",
    "    def __init__(self, bpemb_model, max_length = 100, pre_padding = True):\n",
    "        self.bpemb_model = bpemb_model\n",
    "        self.max_length = max_length\n",
    "\n",
    "        # Get the registered keys and vectors\n",
    "        kv = bpemb_model.emb\n",
    "        key2index = kv.key_to_index\n",
    "        self.vocab = list(key2index.keys())\n",
    "        self.pre_padding = pre_padding\n",
    "        self.n_tokens = len(self.vocab)\n",
    "\n",
    "        # Register the special tokens\n",
    "        self.vocab +=[\"[SOS]\", \"[EOS]\"]\n",
    "\n",
    "        # Extend the vocabulary with the special tokens\n",
    "        self.sos_token_id = self.n_tokens\n",
    "        self.eos_token_id = self.n_tokens + 1\n",
    "        self.n_tokens = self.n_tokens + 2\n",
    "\n",
    "    def tokenize(self, sentences, append_sos):\n",
    "        \"\"\"\n",
    "        Tokenize the sentences into subword vectors\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        sentences: list of str\n",
    "            The list of sentences to be tokenized\n",
    "        append_sos: bool\n",
    "            If True, [SOS] token are appended to the sequences.\n",
    "\n",
    "        Return\n",
    "        ------\n",
    "        output_seqs: Tensor of shape <n_sentences x max_length x n_dim>\n",
    "        \"\"\"\n",
    "\n",
    "        n_sents = len(sentences)\n",
    "        output_token_ids = torch.ones((n_sents, self.max_length), dtype = torch.long) * self.n_tokens\n",
    "\n",
    "        for i, sent in enumerate(sentences):\n",
    "            tokens = self.bpemb_model.encode_ids(sent)\n",
    "            tokens = torch.tensor(tokens, dtype = torch.long)\n",
    "\n",
    "            # Add the special tokens\n",
    "            if append_sos:\n",
    "                tokens = tokens[:np.minimum(self.max_length - 2, len(tokens))]\n",
    "                tokens = np.concatenate([[self.sos_token_id], tokens, [self.eos_token_id]])\n",
    "            else:\n",
    "                tokens = tokens[:np.minimum(self.max_length - 1, len(tokens))]\n",
    "                tokens = np.concatenate([tokens, [self.eos_token_id]])\n",
    "\n",
    "            if self.pre_padding:\n",
    "                output_token_ids[i, :len(tokens)] = torch.tensor(tokens)\n",
    "            else:\n",
    "                output_token_ids[i, -len(tokens):] = torch.tensor(tokens)\n",
    "\n",
    "        return output_token_ids\n",
    "\n",
    "    def get_eos_token(self, n_sents = 1):\n",
    "        \"\"\"\n",
    "        Get the [EOS] token\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_sents: int\n",
    "            The number of sentences to be generated\n",
    "\n",
    "        Return\n",
    "        ------\n",
    "        output: Tensor of shape <n_sents x 1>\n",
    "        \"\"\"\n",
    "        return torch.ones((n_sents, 1), dtype = torch.long) * self.eos_token_id\n",
    "\n",
    "    def get_sos_token(self, n_sents = 1):\n",
    "        \"\"\"\n",
    "        Get the [SOS] token\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_sents: int\n",
    "            The number of sentences to be generated\n",
    "\n",
    "        Return\n",
    "        ------\n",
    "        output: Tensor of shape <n_sents x 1>\n",
    "        \"\"\"\n",
    "        return torch.ones((n_sents, 1), dtype = torch.long) * self.sos_token_id\n",
    "\n",
    "src_tokenizer = Tokenizer(en_bpemb, max_length = 30, pre_padding=False)\n",
    "trg_tokenizer = Tokenizer(fr_bpemb, max_length = 30, pre_padding=True)\n",
    "\n",
    "subword_token_ids = src_tokenizer.tokenize([\"FastText\", \"SlowText\"], append_sos = True)\n",
    "print(\"Subword token ids:\\n\", subword_token_ids)\n",
    "print(\"Shape:\", subword_token_ids.shape) # <n_sentences x max_length x n_dim>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement the seq2seq model \n",
    "\n",
    "### Implementation design \n",
    "\n",
    "The `seq2seq` model consists of an encoder and a decoder, connected by the hidden states. The encoder takes the input sequence and generates the hidden states. The decoder takes the hidden state of the last token, and generate the output sequence.  \n",
    "\n",
    "<img src=\"https://pytorch.org/tutorials/_images/seq2seq.png\" width=\"800\">\n",
    "\n",
    "[Source](https://pytorch.org/tutorials/_images/seq2seq.png)\n",
    "\n",
    "\n",
    "\n",
    " While [the original paper uses the LSTM for the encoder and the decoder](https://arxiv.org/abs/1409.3215), let's use another more efficient RNN, [Gated Recurrent Unit (GRU) by Cho et al.](https://arxiv.org/pdf/1406.1078v3.pdf). In contrast to LSTM, GRU simplifies the architecture by utilizing only a hidden state, omitting the cell state.\n",
    "\n",
    "![gru](https://media.licdn.com/dms/image/C5612AQH5Im8XrvLmYQ/article-cover_image-shrink_600_2000/0/1564974698831?e=2147483647&v=beta&t=mVx-N8AfjAS5L-ktV6vmi_5LxR1madQ16yT1fRu__Jk)\n",
    "\n",
    "### Implementation \n",
    "\n",
    "Let's implement the seq2seq model. We will use [torch's implmentation of the GRU](https://pytorch.org/docs/stable/generated/torch.nn.GRU.html) for the encoder and the decoder. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class Seq2Seq(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        \"\"\"\n",
    "        Initializes the Seq2Seq model with given parameters.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_size : int\n",
    "            The number of expected features in the input `x`\n",
    "        hidden_size : int\n",
    "            The number of features in the hidden state `h`\n",
    "        output_size : int\n",
    "            The number of features in the output\n",
    "        \"\"\"\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        # TODO: Implement\n",
    "        # HINT: Use `torch.nn.Embedding` to embed the input and output tokens. Reserve the last token (src_tokenizer.n_tokens, and trg_tokenizer.n_tokens)for padding.\n",
    "        # HINT: Use the `torch.nn.GRU` for the encoder and the decoder. Use `batch_first = True`.\n",
    "        # HINT: Define two `torch.nn.Linear` and ReLu to map the hidden state of the decorder to the output\n",
    "        self.src_emb = torch.nn.Embedding(src_tokenizer.n_tokens+1, input_size, padding_idx = src_tokenizer.n_tokens)\n",
    "        self.trg_emb = torch.nn.Embedding(trg_tokenizer.n_tokens+1, output_size, padding_idx = trg_tokenizer.n_tokens)\n",
    "        self.encoder = torch.nn.GRU(input_size, hidden_size, batch_first=True) # batch_first means the input and output tensors are provided as (batch, sequence, feature)\n",
    "        self.decoder = torch.nn.GRU(input_size, hidden_size, batch_first=True)\n",
    "        self.lin_out_1 = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.lin_out_2 = torch.nn.Linear(hidden_size, output_size)\n",
    "        self.non_activation = torch.nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        -----\n",
    "        inputs: Tensor of shape <batch_size x sequence_length>\n",
    "\n",
    "        Return\n",
    "        ----\n",
    "        hidden: Tensor of shape <1 x hidden_size>\n",
    "        \"\"\"\n",
    "        batch_size = inputs.shape[0]\n",
    "\n",
    "        # TODO: Embed the input tokens\n",
    "        inputs = self.src_emb(inputs) # <batch_size x sequence_length x input_size>\n",
    "\n",
    "        # TODO: Initiailize the hidden states\n",
    "        # Hint: See the input for the GRU module: https://pytorch.org/docs/stable/generated/torch.nn.GRU.html\n",
    "        hidden_state = torch.zeros(1, batch_size, self.hidden_size, dtype=torch.float32)\n",
    "\n",
    "        # TODO: Run the encoder\n",
    "        _, hidden = self.encoder(inputs, hidden_state)\n",
    "        return hidden\n",
    "\n",
    "    def decode(self, hidden_states, inputs):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        hidden_states: Tensor of shape <batch x hidden_size>\n",
    "        inputs: Tensor of shape <batch x 1 x input_size>\n",
    "\n",
    "        Return\n",
    "        ------\n",
    "        output: Tensor of shape <batch x output_size>\n",
    "        \"\"\"\n",
    "\n",
    "        inputs = self.trg_emb(inputs)\n",
    "\n",
    "        # TODO: Implement the decoder\n",
    "        output, hidden = self.decoder(inputs, hidden_states)\n",
    "\n",
    "        # TODO: Pass the output through the MLP consisting of two linear layers with one ReLu in betweeen.\n",
    "        output = self.lin_out_1(output)\n",
    "        output = self.non_activation(output)\n",
    "        output = self.lin_out_2(output)\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "dim = 256\n",
    "hidden_dim = 128\n",
    "seq2seq = Seq2Seq(input_size = dim, hidden_size = hidden_dim, output_size = dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequense size <n_sentences x max_length>: torch.Size([2, 30])\n",
      "Hidden state size is <1, n_sentences, hidden_size> torch.Size([1, 2, 128])\n",
      "[SOS] token id tensor([[1000],\n",
      "        [1000]])\n",
      "Size of the hidden state from the decoder: <1, n_sentences, n_dim>: torch.Size([1, 2, 128])\n",
      "Size of the output from the decoder: <n_sentences, 1, n_dim>: torch.Size([2, 1, 256])\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "seq2seq.eval()\n",
    "\n",
    "test_text = [\"FastText\", \"SlowText\"]\n",
    "in_tokens = src_tokenizer.tokenize(test_text, append_sos = False)\n",
    "print(\"Sequense size <n_sentences x max_length>:\", in_tokens.shape)\n",
    "\n",
    "# TODO: Compute the last hidden state of the encoder\n",
    "hidden = seq2seq(in_tokens)\n",
    "print(\"Hidden state size is <1, n_sentences, hidden_size>\", hidden.shape)\n",
    "\n",
    "# The first input to the decoder is the [SOS] token.\n",
    "# The id for the [SOS] token can be generated by `get_sos_token` API\n",
    "inputs = trg_tokenizer.get_sos_token(n_sents = 2)\n",
    "print(\"[SOS] token id\", inputs)\n",
    "\n",
    "# TODO: Run the decoder and generate one token\n",
    "output, hidden = seq2seq.decode(hidden, inputs)\n",
    "\n",
    "print(\"Size of the hidden state from the decoder: <1, n_sentences, n_dim>:\", hidden.shape)\n",
    "print(\"Size of the output from the decoder: <n_sentences, 1, n_dim>:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the seq2seq model\n",
    "\n",
    "## Loss\n",
    "\n",
    "While the original seq2seq uses the Cross Entropy Loss, we will use a more efficient negative sampling loss, which works as follows: \n",
    "1. We will sample a few $k$ random words (i.e., negative examples) from the vocabulary uniformly at random. \n",
    "2. Convert the negative examples (i.e., words) into word embeddings.  \n",
    "3. Compute the similarity (1) between the output from the decoder and the target word embedding, and (2) beween the negative word embeddings and the true word embedding.\n",
    "4. Compute the binary cross entropy loss between the similarity values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NegativeSamplingLoss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, n_negatives):\n",
    "        super(NegativeSamplingLoss, self).__init__()\n",
    "        self.n_negatives = n_negatives\n",
    "        self.loss = torch.nn.BCEWithLogitsLoss(reduction = \"mean\")\n",
    "\n",
    "    def forward(self, input_vecs, target_vecs, seq2seq, mask = None):\n",
    "        \"\"\"\n",
    "        input_vecs: <batch_size>\n",
    "        target_vecs: <batch_size>\n",
    "        \"\"\"\n",
    "        input_vecs = input_vecs.repeat(1, self.n_negatives, 1)\n",
    "        target_vecs = target_vecs.repeat(1, self.n_negatives, 1)\n",
    "\n",
    "        if mask is not None:\n",
    "            input_vecs = input_vecs[~mask]\n",
    "            target_vecs = target_vecs[~mask]\n",
    "\n",
    "        batch_size = input_vecs.shape[0]\n",
    "\n",
    "        if batch_size < 1:\n",
    "            return 0\n",
    "        negative_vecs = seq2seq.trg_emb(torch.randint(0, seq2seq.trg_emb.num_embeddings-1, (batch_size, self.n_negatives)))\n",
    "\n",
    "        pos = torch.sum(input_vecs * target_vecs, dim = 2).view(-1)\n",
    "        neg = torch.sum(input_vecs * negative_vecs, dim = 2).view(-1)\n",
    "\n",
    "        pred = torch.cat([pos, neg])\n",
    "        target = torch.cat([torch.ones_like(pos), torch.zeros_like(neg)])\n",
    "\n",
    "        return self.loss(pred, target)\n",
    "\n",
    "loss = NegativeSamplingLoss(n_negatives = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset & Data loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, dataframe, source_col=\"source\", target_col=\"target\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataframe (pandas.DataFrame): DataFrame containing the source and target sentences.\n",
    "            source_col (str): The name of the column containing the source sentences.\n",
    "            target_col (str): The name of the column containing the target sentences.\n",
    "        \"\"\"\n",
    "        self.dataframe = dataframe\n",
    "        self.source_col = source_col\n",
    "        self.target_col = target_col\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        source_sentence = self.dataframe.loc[idx, self.source_col]\n",
    "        target_sentence = self.dataframe.loc[idx, self.target_col]\n",
    "\n",
    "\n",
    "        return source_sentence, target_sentence\n",
    "\n",
    "# Assuming `train_data` is a pandas DataFrame containing the source and target sentences\n",
    "translation_dataset = TranslationDataset(train_data)\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(translation_dataset, batch_size=1024, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(seq2seq.parameters(), lr=5e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.06285: 100%|██████████| 10/10 [01:07<00:00,  6.20s/it]  "
     ]
    },
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (src_emb): Embedding(1003, 256, padding_idx=1002)\n",
       "  (trg_emb): Embedding(1003, 256, padding_idx=1002)\n",
       "  (encoder): GRU(256, 128, batch_first=True)\n",
       "  (decoder): GRU(256, 128, batch_first=True)\n",
       "  (lin_out_1): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (lin_out_2): Linear(in_features=128, out_features=256, bias=True)\n",
       "  (non_activation): LeakyReLU(negative_slope=0.01)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "n_epochs = 1\n",
    "loss_values = []\n",
    "seq2seq.train()\n",
    "\n",
    "pbar = tqdm(total=len(train_loader) * n_epochs)\n",
    "\n",
    "loss2 = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # TODO: Implement the training loop\n",
    "        in_tokens = src_tokenizer.tokenize(inputs, append_sos = False)\n",
    "        out_tokens = trg_tokenizer.tokenize(targets, append_sos = True)\n",
    "\n",
    "        decoder_hidden = seq2seq(in_tokens)\n",
    "\n",
    "        loss_value = 0\n",
    "        for i in range(out_tokens.shape[1]-1):\n",
    "            decoder_inputs = out_tokens[:, i].unsqueeze(1)\n",
    "            output, decoder_hidden = seq2seq.decode(decoder_hidden, decoder_inputs)\n",
    "\n",
    "            target_tokens = out_tokens[:, i+1].unsqueeze(1)\n",
    "#            scores = output.squeeze(1) @ trg_tokenizer.vectors.T\n",
    "#\n",
    "#            target_ids = out_token_ids[:, i+1].to(torch.long)\n",
    "#            mask = target_ids == -1\n",
    "#            loss_value+=loss2(scores[~mask], target_ids[~mask])\n",
    "            target_vecs = seq2seq.trg_emb(target_tokens)\n",
    "            loss_value+= loss(output, target_tokens, seq2seq)\n",
    "\n",
    "        #loss_value /= out_tokens.shape[0]\n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_value = loss_value.item()\n",
    "\n",
    "        pbar.update(1)\n",
    "        pbar.set_description(f\"Loss: {loss_value:.5f}\")\n",
    "        loss_values.append(loss_value)\n",
    "\n",
    "seq2seq.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "sns.set(font_scale=1.2)\n",
    "sns.set_style('ticks')\n",
    "fig, ax = plt.subplots(figsize=(7,5))\n",
    "\n",
    "ax.plot(loss_values)\n",
    "ax.set_xlabel(\"Batch\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_title(\"Training Loss\")\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0695,  0.6677, -2.0073,  ..., 12.5573,  3.6371,  0.0000]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "tensor([[ 1.6101,  0.0123, -0.8961,  ..., 10.1091,  4.5737,  0.0000]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "tensor([[2.2678, 0.4254, 0.1802,  ..., 9.6101, 4.2351, 0.0000]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "tensor([[2.8008, 0.4318, 0.5856,  ..., 9.2753, 3.6412, 0.0000]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "tensor([[3.2038, 0.3377, 0.7271,  ..., 8.9645, 3.3869, 0.0000]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "tensor([[3.4390, 0.2568, 0.6477,  ..., 8.7653, 3.3339, 0.0000]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "tensor([[3.5723, 0.2412, 0.5670,  ..., 8.6960, 3.3242, 0.0000]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "tensor([[3.6212, 0.2079, 0.5113,  ..., 8.7385, 3.3439, 0.0000]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "tensor([[3.6472, 0.1666, 0.4616,  ..., 8.8023, 3.3752, 0.0000]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "tensor([[3.6592, 0.1360, 0.4176,  ..., 8.8487, 3.3997, 0.0000]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "tensor([[3.6632, 0.1111, 0.3848,  ..., 8.8893, 3.4167, 0.0000]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "tensor([[3.6653, 0.0902, 0.3556,  ..., 8.9283, 3.4286, 0.0000]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "tensor([[3.6669, 0.0740, 0.3258,  ..., 8.9629, 3.4368, 0.0000]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "tensor([[3.6659, 0.0613, 0.3018,  ..., 8.9926, 3.4434, 0.0000]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "tensor([[3.6630, 0.0509, 0.2830,  ..., 9.0186, 3.4491, 0.0000]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "tensor([[3.6576, 0.0415, 0.2688,  ..., 9.0425, 3.4541, 0.0000]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "tensor([[3.6497, 0.0322, 0.2582,  ..., 9.0653, 3.4584, 0.0000]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "tensor([[3.6401, 0.0228, 0.2510,  ..., 9.0854, 3.4630, 0.0000]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "tensor([[3.6262, 0.0102, 0.2489,  ..., 9.1034, 3.4687, 0.0000]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "tensor([[ 3.6130e+00, -8.5807e-04,  2.4742e-01,  ...,  9.1193e+00,\n",
      "          3.4743e+00,  0.0000e+00]], grad_fn=<MmBackward0>)\n",
      "tensor([[ 3.6006, -0.0107,  0.2464,  ...,  9.1335,  3.4798,  0.0000]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "tensor([[ 3.5890, -0.0194,  0.2456,  ...,  9.1461,  3.4851,  0.0000]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "tensor([[ 3.5781, -0.0272,  0.2449,  ...,  9.1573,  3.4904,  0.0000]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "tensor([[ 3.5679, -0.0343,  0.2443,  ...,  9.1674,  3.4955,  0.0000]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "tensor([[ 3.5585, -0.0406,  0.2436,  ...,  9.1765,  3.5004,  0.0000]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "tensor([[ 3.5497, -0.0463,  0.2430,  ...,  9.1846,  3.5051,  0.0000]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "tensor([[ 3.5416, -0.0514,  0.2423,  ...,  9.1920,  3.5096,  0.0000]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "tensor([[ 3.5340, -0.0561,  0.2416,  ...,  9.1986,  3.5139,  0.0000]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "tensor([[ 3.5271, -0.0603,  0.2409,  ...,  9.2047,  3.5180,  0.0000]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "tensor([[ 3.5207, -0.0642,  0.2401,  ...,  9.2101,  3.5219,  0.0000]],\n",
      "       grad_fn=<MmBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['man',\n",
       " 'man',\n",
       " 'man',\n",
       " 'man',\n",
       " 'man',\n",
       " 'man',\n",
       " 'man',\n",
       " 'man',\n",
       " 'man',\n",
       " 'man',\n",
       " 'man',\n",
       " 'man',\n",
       " 'man',\n",
       " 'man',\n",
       " 'man',\n",
       " 'man',\n",
       " 'man',\n",
       " 'man',\n",
       " 'man',\n",
       " 'man',\n",
       " 'man',\n",
       " 'man',\n",
       " 'man',\n",
       " 'man',\n",
       " 'man',\n",
       " 'man',\n",
       " 'man',\n",
       " 'man',\n",
       " 'man',\n",
       " 'man']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_sequence(sentence, seq2seq, src_tokenizer, trg_tokenizer, max_length, temperature = 0.3):\n",
    "    in_seqs = src_tokenizer.tokenize([sentence], append_sos = False)\n",
    "    decoder_hidden = seq2seq(in_seqs)\n",
    "\n",
    "    decoder_inputs = trg_tokenizer.get_sos_token()\n",
    "    softmax = torch.nn.Softmax(dim = 1)\n",
    "    out_seq = []\n",
    "    for _ in range(max_length):\n",
    "        output, decoder_hidden = seq2seq.decode(decoder_hidden, decoder_inputs)\n",
    "        scores = output.squeeze(1) @ seq2seq.trg_emb.weight.T\n",
    "        prob = softmax(scores / temperature)\n",
    "        print(scores)\n",
    "        idx = torch.argmax(prob, dim = 1)\n",
    "        decoder_inputs = torch.ones((1, 1), dtype = torch.long) * idx\n",
    "\n",
    "        out_seq.append(trg_tokenizer.vocab[idx])\n",
    "\n",
    "        if idx == trg_tokenizer.eos_token_id:\n",
    "            break\n",
    "    return out_seq\n",
    "\n",
    "seq2seq.eval()\n",
    "generate_sequence(\"Chao.\", seq2seq, src_tokenizer, trg_tokenizer, max_length = 30, temperature = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "applsoftcomp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
